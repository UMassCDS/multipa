{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Additional Modeling Pipelines\n",
    "We should also compare performance in the evaluation data with other readily available phonetic transcription options, to determine whether fine-tuning your own model is worth the effort. \n",
    "The two options we consider here are: \n",
    "- Wav2vec2 fine tuned on TIMIT (https://huggingface.co/elgeish/wav2vec2-large-lv60-timit-asr) as the speech recognition model, followed by using [epitran](https://github.com/dmort27/epitran) to convert othography to IPA. The TIMIT corpus is a high quality corpus of read English speech.\n",
    "- [Allosaurus](https://github.com/xinjli/allosaurus) is a pre-trained universal phone recognizer that claims to recognize phones in more than 2000 languages. \n",
    "- [Whisper](https://openai.com/index/whisper/) is the state-of-the-art sequence-to-sequence speech recognition model released by OpenAI. Details about the different model releases are available at https://github.com/openai/whisper/blob/main/model-card.md. There are multilingual and English fine-tuned versions.\n",
    "\n",
    "These evaluations only need to be run and computed once. \n",
    "\n",
    "## Additional installation step for Epitran\n",
    "To use Epitran for English, you also need to install https://github.com/festvox/flite. See the Epitran note at https://github.com/dmort27/epitran?tab=readme-ov-file#installation-of-flite-for-english-g2p.  I installed Flite on my mac:\n",
    "\n",
    "```bash\n",
    "$ git clone http://github.com/festvox/flite\n",
    "$ cd flite\n",
    "$ ./configure && make\n",
    "$ sudo make install\n",
    "$ cd testsuite\n",
    "$ make lex_lookup\n",
    "$ sudo cp lex_lookup /usr/local/bin\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import allosaurus.app\n",
    "import allosaurus.bin.download_model\n",
    "import epitran\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from multipa.data_utils import load_buckeye_split\n",
    "from multipa.evaluate import ModelEvaluator, preprocess_test_data, DETAILED_PREDICTIONS_CSV_SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allosaurus_predict(test_dataset, model=\"eng2102\", phone_inventory=\"ipa\"):\n",
    "    print(\"Evaluating allosaurus. Model:\", model, \"Phone inventory:\", phone_inventory)\n",
    "    model_predictions = []\n",
    "    model = allosaurus.app.read_recognizer(model)\n",
    "    start = time.time()\n",
    "    for audio in tqdm(test_dataset[\"audio\"]):\n",
    "        prediction = model.recognize(audio[\"path\"], phone_inventory)\n",
    "        prediction = prediction.replace(\" \", \"\")\n",
    "        model_predictions.append(prediction)\n",
    "    end = time.time()\n",
    "    print(\"Eval time in seconds:\", end-start)\n",
    "    return model_predictions\n",
    "\n",
    "def hf_model_to_epitran_predict(model_name, test_dataset):\n",
    "    print(\"Building pipeline and downloading model\")\n",
    "    pipe = transformers.pipeline(\"automatic-speech-recognition\", model=model_name)\n",
    "    print(\"Predicting with\", model_name)\n",
    "    start = time.time()\n",
    "    orthography_predictions = [d[\"text\"] for d in pipe(test_dataset[\"audio\"])]\n",
    "    epi = epitran.Epitran('eng-Latn')\n",
    "    print(\"Transliterating with Epitran\")\n",
    "    ipa_predictions = []\n",
    "    for pred in tqdm(orthography_predictions):\n",
    "        result = epi.transliterate(pred).replace(\" \", \"\")\n",
    "        ipa_predictions.append(result)\n",
    "    end = time.time()\n",
    "    print(\"Eval time in seconds:\", end-start)\n",
    "    return ipa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 37566/37566 [00:00<00:00, 230004.87it/s]\n",
      "Resolving data files: 100%|██████████| 10160/10160 [00:00<00:00, 29160.30it/s]\n",
      "Resolving data files: 100%|██████████| 11212/11212 [00:00<00:00, 689326.40it/s]\n",
      "WARNING:datasets.builder:Using custom data configuration default-7ae042e163b5e2c1\n",
      "WARNING:datasets.builder:Found cached dataset audiofolder (/Users/virginia/.cache/huggingface/datasets/audiofolder/default-7ae042e163b5e2c1/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview\n",
      "Dataset({\n",
      "    features: ['audio', 'utterance_id', 'duration', 'buckeye_transcript', 'text', 'ipa', 'speaker_id', 'speaker_gender', 'speaker_age_range', 'interviewer_gender', 'file_path', '__index_level_0__'],\n",
      "    num_rows: 5079\n",
      "})\n",
      "{'audio': {'bytes': None, 'path': '/Users/virginia/workspace/multipa/data/buckeye/test/s2501a_Utt0.wav'}, 'utterance_id': 's2501a_Utt0', 'duration': 0.925981, 'buckeye_transcript': 'f ao r f ay v', 'text': 'four five', 'ipa': 'f ɔ ɹ f aɪ v', 'speaker_id': 'S25', 'speaker_gender': 'f', 'speaker_age_range': 'o', 'interviewer_gender': 'm', 'file_path': 'data/buckeye/test/s2501a_Utt0.wav', '__index_level_0__': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [00:00<00:00, 14530.44ex/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.40ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples with empty transcriptions: 0\n",
      "Dataset({\n",
      "    features: ['audio', 'utterance_id', 'duration', 'buckeye_transcript', 'text', 'ipa', 'speaker_id', 'speaker_gender', 'speaker_age_range', 'interviewer_gender', 'file_path', '__index_level_0__'],\n",
      "    num_rows: 0\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  5.15ba/s]\n"
     ]
    }
   ],
   "source": [
    "input_data = load_buckeye_split(\"../data/buckeye\", \"test\")\n",
    "# Snippet of transcriptions\n",
    "# Note that there don't appear to be any non-empty transcriptions,\n",
    "# so this notebook skips looking at hallucinations\n",
    "print(\"Data Preview\")\n",
    "print(input_data)\n",
    "print(input_data[0])\n",
    "\n",
    "non_empty_test_data, empty_test_data = preprocess_test_data(input_data, is_remove_space=True)\n",
    "\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline and downloading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with openai/whisper-large-v3-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating with Epitran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [07:24<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 23151.309972286224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 16.71ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1401: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 95.77ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline and downloading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with openai/whisper-large-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating with Epitran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [04:47<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 37418.261837005615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 15.26ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1401: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 95.00ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline and downloading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with openai/whisper-medium.en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliterating with Epitran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [10:48<00:00,  7.83it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 14702.21756529808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00,  7.89ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1401: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 55.67ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline and downloading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at elgeish/wav2vec2-large-lv60-timit-asr were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at elgeish/wav2vec2-large-lv60-timit-asr and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with elgeish/wav2vec2-large-lv60-timit-asr\n",
      "Transliterating with Epitran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [12:24<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 2219.9671170711517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 15.72ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1401: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 97.09ba/s]\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    \"openai/whisper-large-v3-turbo\",\n",
    "    \"openai/whisper-large-v3\",\n",
    "    \"openai/whisper-medium.en\",\n",
    "    \"elgeish/wav2vec2-large-lv60-timit-asr\",\n",
    "]\n",
    "for m in models:\n",
    "    # Epitran\n",
    "    epitran_predictions = hf_model_to_epitran_predict(m, non_empty_test_data)\n",
    "    model_name = f\"{m}_to_epitran\".replace(\"/\", \"_\")\n",
    "    epitran_detailed_csv = f\"{model_name}_{DETAILED_PREDICTIONS_CSV_SUFFIX}\"\n",
    "    metrics = model_evaluator.eval_non_empty_transcriptions(\n",
    "        model_name, epitran_predictions, non_empty_test_data[\"ipa\"]\n",
    "    )\n",
    "    detailed_results = non_empty_test_data.add_column(\n",
    "        \"prediction\", epitran_predictions\n",
    "    ).remove_columns([\"audio\"])\n",
    "    for k in [\"phone_error_rates\", \"phone_feature_error_rates\", \"feature_error_rates\"]:\n",
    "        detailed_results = detailed_results.add_column(k, metrics[k])\n",
    "    detailed_results.remove_columns([\"__index_level_0__\"]).to_csv(\n",
    "        epitran_detailed_csv, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/allosaurus/am/utils.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(str(path), map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating allosaurus. Model: uni2005 Phone inventory: ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2269/5079 [05:27<09:54,  4.73it/s]/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/allosaurus/pm/utils.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  return (feature - spk_mean)/spk_std\n",
      "100%|██████████| 5079/5079 [29:31<00:00,  2.87it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 1774.002643108368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 17.01ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1401: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/datasets/table.py:1427: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 107.37ba/s]\n",
      "/Users/virginia/miniconda3/envs/multipa/lib/python3.11/site-packages/allosaurus/am/utils.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(str(path), map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating allosaurus. Model: uni2005 Phone inventory: eng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [17:11<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 1033.3425288200378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 16.64ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 101.72ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating allosaurus. Model: eng2102 Phone inventory: ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [23:28<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 1410.6358399391174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 16.45ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 107.43ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating allosaurus. Model: eng2102 Phone inventory: eng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [25:59<00:00,  3.26it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time in seconds: 1561.5043210983276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 6/6 [00:00<00:00, 10.78ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 62.67ba/s]\n"
     ]
    }
   ],
   "source": [
    "# Define models and phone inventory to test\n",
    "allosaurus_models = [\"uni2005\", \"eng2102\"]\n",
    "phone_inventory = [\"ipa\", \"eng\"]\n",
    "\n",
    "# Download models\n",
    "for m in allosaurus_models:\n",
    "    allosaurus.bin.download_model.download_model(m)\n",
    "\n",
    "# Predict and check against gold standard\n",
    "for model, pi in itertools.product(allosaurus_models, phone_inventory):\n",
    "    model_predictions = allosaurus_predict(non_empty_test_data, model, pi)\n",
    "    model_name = f\"allosaurus_{model}_{pi}\"\n",
    "    detailed_results_csv = f\"{model_name}_{DETAILED_PREDICTIONS_CSV_SUFFIX}\"\n",
    "    metrics = model_evaluator.eval_non_empty_transcriptions(model_name, model_predictions, non_empty_test_data[\"ipa\"])\n",
    "    detailed_results = non_empty_test_data.add_column(\"prediction\", model_predictions).\\\n",
    "                remove_columns([\"audio\"])\n",
    "    for k in [\"phone_error_rates\", \"phone_feature_error_rates\", \"feature_error_rates\"]:\n",
    "        detailed_results = detailed_results.add_column(k, metrics[k])\n",
    "    detailed_results.remove_columns([\"__index_level_0__\"]).to_csv(detailed_results_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all results to file for comparison\n",
    "model_evaluator.to_csv(\"epitran_allosaurus_eval.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

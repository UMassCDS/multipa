{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload experimental models to Hugging Face Model repositories\n",
    "This notebook is a helper for uploading pre-trained models to Hugging Face. It allows you to add README info for experiments at upload time for better documentation. \n",
    "\n",
    "*First*: Make sure that you have added your HuggingFace Hub token in some way or logged in on the command line via `huggingface-cli login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_vcpartridge_umass_edu/multipa/env_cuda124/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "import transformers\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name prefix to \n",
    "MODEL_ROOT = Path(\"../data/models/\")\n",
    "ALL_MODELS_README = \"\"\"\n",
    "---\n",
    "license: mit\n",
    "language:\n",
    "- en\n",
    "pipeline_tag: automatic-speech-recognition\n",
    "---\n",
    "# About \n",
    "This model was created to support experiments for evaluating phonetic transcription \n",
    "with the Buckeye corpus as part of https://github.com/ginic/multipa. \n",
    "This is a version of facebook/wav2vec2-large-xlsr-53 fine tuned on a specific subset of the Buckeye corpus.\n",
    "For details about specific model parameters, please view the config.json here or \n",
    "training scripts in the scripts/buckeye_experiments folder of the GitHub repository. \n",
    "\n",
    "# Experiment Details\n",
    "\"\"\"\n",
    "\n",
    "# Specific sets of experiments have more details. I just copied these from the EXPERIMENT_LOG.md \n",
    "README_MAPPINGS = {\n",
    "#     # This was the best hyperparam tuned model & these model parameters were used for all other experiments\n",
    "#     \"hyperparam_tuning_1\":\"\"\"The best performing model from hyperparameter tuning experiments (batch size, learning rat, base model to fine tune). Vary the random seed to select training data while keeping an even 50/50 gender split to measure statistical significance of changing training data selection. Retrain with the same model parameters, but different data seeding to measure statistical significance of data seed, keeping 50/50 gender split. \n",
    "\n",
    "# Goals: \n",
    "# - Choose initial hyperparameters (batch size, learning rat, base model to fine tune) based on validation set performance\n",
    "# - Establish whether data variation with the same gender makeup is statistically significant in changing performance on the test set (first data_seed experiment)\n",
    "# \"\"\",\n",
    "#     \"data_seed_bs64\": \"\"\"Vary the random seed to select training data while keeping an even 50/50 gender split to measure statistical significance of changing training data selection. Retrain with the same model parameters, but different data seeding to measure statistical significance of data seed, keeping 50/50 gender split. \n",
    "\n",
    "# Goals: \n",
    "# - Establish whether data variation with the same gender makeup is statistically significant in changing performance on the test set\n",
    "\n",
    "# Params to vary:\n",
    "# - training data seed (--train_seed): [91, 114, 771, 503]\n",
    "# \"\"\",\n",
    "\n",
    "#     \"gender_split\": \"\"\"Still training with a total amount of data equal to half the full training data (4000 examples), vary the gender split 30/70, but draw examples from all individuals. Do 5 models for each gender split with the same model parameters but different data seeds. \n",
    "\n",
    "# Goals: \n",
    "# - Determine how different in gender split in training data affects performance\n",
    "\n",
    "# Params to vary: \n",
    "# - percent female (--percent_female) [0.3, 0.7]\n",
    "# - training seed (--train_seed)\n",
    "# \"\"\", \n",
    "\n",
    "#     \"vary_individuals\": \"\"\"These experiments keep the total amount of data equal to half the training data with the gender split 50/50, but further exclude certain speakers completely using the --speaker_restriction argument. This allows us to restrict speakers included in training data in any way. For the purposes of these experiments, we are focussed on the age demogrpahic of the user.  \n",
    "\n",
    "# For reference, the speakers and their demographics included in the training data are as follows where the speaker age range 'y' means under 30 and 'o' means over 40: \n",
    "\n",
    "# | speaker_id | speaker_gender | speaker_age_range | \n",
    "# | ---------- | -------------- | ----------------- |\n",
    "# | S01 | f | y |\n",
    "# | S04 | f | y | \n",
    "# | S08 | f | y | \n",
    "# | S09 | f | y | \n",
    "# | S12 | f | y | \n",
    "# | S21 | f | y | \n",
    "# | S02 | f | o |\n",
    "# | S05 | f | o | \n",
    "# | S07 | f | o | \n",
    "# | S14 | f | o | \n",
    "# | S16 | f | o |\n",
    "# | S17 | f | o | \n",
    "# | S06 | m | y | \n",
    "# | S11 | m | y | \n",
    "# | S13 | m | y | \n",
    "# | S15 | m | y | \n",
    "# | S28 | m | y | \n",
    "# | S30 | m | y |\n",
    "# | S03 | m | o | \n",
    "# | S10 | m | o | \n",
    "# | S19 | m | o |\n",
    "# | S22 | m | o |\n",
    "# | S24 | m | o | \n",
    "\n",
    "\n",
    "# Goals: \n",
    "# - Determine how variety of speakers in the training data affects performance\n",
    "\n",
    "# Params to vary: \n",
    "# - training seed (--train_seed)\n",
    "# - demographic make up of training data by age, using --speaker_restriction \n",
    "#     - Experiments `young_only`: only individuals under 30, S01 S04 S08 S09 S12 S21 S06 S11 S13 S15 S28 S30\n",
    "#     - Experiments `old_only`: only individuals over 40, S02 S05 S07 S14 S16 S17 S03 S10 S19 S22 S24\n",
    "# \"\"\"\n",
    "    \"full_dataset\": \"\"\"The entire Buckeye corpus, including the sets that were held out for validation and/or testing in our original experiments with Buckeye, are used to train the model. \n",
    "The \"full_dataset_train_val\" used both training and validation splits in model training and the \"full_dataset_train_val_test\" used all splits (training, validation, test) in model training. As a result, the held out test set of Buckeye should used to establish performance benchmarks for these models.\n",
    "\n",
    "Goals: \n",
    "- Include the largest amount of training data possible. \n",
    "- Can be used with a different corpus (e.g. TIMIT, Speech Accent Archive) for evaluation to test generalization to other dialects and language varieties. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ../data/models/vary_individuals_old_only_1 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_old_only_1_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:23<00:00, 53.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_old_only_1_wav2vec2-large-xlsr-53-buckeye-ipa\n",
      "Model ../data/models/vary_individuals_old_only_2 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_old_only_2_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:22<00:00, 55.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_old_only_2_wav2vec2-large-xlsr-53-buckeye-ipa\n",
      "Model ../data/models/vary_individuals_old_only_3 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_old_only_3_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:28<00:00, 43.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_old_only_3_wav2vec2-large-xlsr-53-buckeye-ipa\n",
      "Model ../data/models/vary_individuals_young_only_1 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_young_only_1_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:23<00:00, 54.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_young_only_1_wav2vec2-large-xlsr-53-buckeye-ipa\n",
      "Model ../data/models/vary_individuals_young_only_2 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_young_only_2_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:26<00:00, 47.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_young_only_2_wav2vec2-large-xlsr-53-buckeye-ipa\n",
      "Model ../data/models/vary_individuals_young_only_3 matches prefix 'vary_individuals'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to hub as: ginic/vary_individuals_young_only_3_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:23<00:00, 53.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading README for ginic/vary_individuals_young_only_3_wav2vec2-large-xlsr-53-buckeye-ipa\n"
     ]
    }
   ],
   "source": [
    "api = HfApi()\n",
    "for model_folder in MODEL_ROOT.iterdir():\n",
    "    if model_folder.is_dir(): \n",
    "        for prefix in README_MAPPINGS.keys(): \n",
    "            if model_folder.name.startswith(prefix):\n",
    "                print(f\"Model {model_folder} matches prefix '{prefix}'.\")\n",
    "                hub_name = f\"ginic/{model_folder.name}_wav2vec2-large-xlsr-53-buckeye-ipa\" \n",
    "        \n",
    "                full_readme = \"\".join([ALL_MODELS_README, README_MAPPINGS[prefix]])\n",
    "                model_to_upload = model_folder / \"wav2vec2-large-xlsr-53-buckeye-ipa\"\n",
    "                readme_path = model_to_upload / \"README.md\"\n",
    "                readme_path.write_text(full_readme)\n",
    "\n",
    "                model_pipeline = transformers.pipeline(\"automatic-speech-recognition\", model=model_to_upload)\n",
    "                print(\"Uploading to hub as:\", hub_name)\n",
    "                model_pipeline.push_to_hub(hub_name)\n",
    "                print(\"Uploading README for\", hub_name)\n",
    "                api.upload_file(\n",
    "                    path_or_fileobj = readme_path, \n",
    "                    path_in_repo = \"README.md\",\n",
    "                    repo_id = hub_name, \n",
    "                    repo_type = \"model\"\n",
    "                )\n",
    "\n",
    "                # Don't look at other prefix keys, the model is already uploaded\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration clean-88debf4c1ba2b8fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac', 'audio': {'path': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac', 'array': array([ 0.14205933,  0.20620728,  0.27151489, ...,  0.00402832,\n",
      "       -0.00628662, -0.01422119]), 'sampling_rate': 16000}, 'duration_ms': 14920, 'text': \"i wanted this to share a few things but i'm going to not share as much as i wanted to share because we are starting late i'd like to get this thing going so we all get home at a decent hour this this election is very important to\"}, {'id': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.flac', 'audio': {'path': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00001.flac', 'array': array([-0.01480103,  0.05319214, -0.0105896 , ..., -0.02996826,\n",
      "        0.06680298,  0.0071106 ]), 'sampling_rate': 16000}, 'duration_ms': 14530, 'text': \"state we support agriculture to the tune of point four percent no way i made a mistake this year they lowered it from point four percent to point three eight percent and in the same breath they're saying food\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual text: i wanted this to share a few things but i'm going to not share as much as i wanted to share because we are starting late i'd like to get this thing going so we all get home at a decent hour this this election is very important to\n",
      "prediction: {'text': 'ɑwɑɾ̃ɪtzɪzdʒɪʃɛɹfjuθɪŋzbʌɾʌmɡʌɾ̃ʌznɑtʃɛɹʌzmʌtʃzʌwɑñɪdɪʃɛɹbɪkʌzwiɑɹstɑɹɾɪɡliadlaɪktɪɡɛttðɪsθɪŋɡoʊʌnsʌwiɡɔɡɛɾhoʊmʌɾʌdisʌnaʊɹ̩ʌmðɪsðɪsʌlɛkʃɪnɪzʌmvɛɹiɪmpɔɹʔn̩tu'}\n",
      "actual text: state we support agriculture to the tune of point four percent no way i made a mistake this year they lowered it from point four percent to point three eight percent and in the same breath they're saying food\n",
      "prediction: {'text': 'steɪwisʌpoʊɹɾæɡɹ̩kʌltʃɹ̩tɪðɪtunʌvpɔɪnfɔɹpɹ̩sɛnoʊnoʊwɪaɪmɪɾʌmʌsteɪkðɪʃjɪɹ̩ðeɪloʊɹ̩dɪtfɹʌmpɔɪntfoʊɹpɹ̩sɛntʌpɔɪntθɹieɪpɹ̩sɛɛɾ̃ɪnðʌseɪmɡɹɛθðɛɹ̩seɪmfuts'}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that upload worked and the model from the hub can be used for inference\n",
    "from multipa.data_utils import load_buckeye_split\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"MLCommons/peoples_speech\", split=\"train\", streaming=True).take(2)\n",
    "dataset = dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16_000))\n",
    "print(list(dataset))\n",
    "pipe = transformers.pipeline(\"automatic-speech-recognition\", model=\"ginic/vary_individuals_old_only_1_wav2vec2-large-xlsr-53-buckeye-ipa\")\n",
    "for i in list(dataset): \n",
    "    pred = pipe(i[\"audio\"])\n",
    "    print(\"actual text:\", i[\"text\"])\n",
    "    print(\"prediction:\", pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
